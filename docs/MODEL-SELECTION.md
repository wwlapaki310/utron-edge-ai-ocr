# OCRãƒ¢ãƒ‡ãƒ«é¸å®šã¨å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚´ãƒ¼ãƒ«

**ã€ŒOCRãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã—ã¦ã€æ–‡å­—å‡ºåŠ›ã•ã‚Œã‚‹ã“ã¨ã€**

---

## 1. æ¨å¥¨OCRãƒ¢ãƒ‡ãƒ«ã®é¸æŠ

### âœ… æ¨å¥¨Option 1: **PaddleOCR-Lite** (æœ€æ¨å¥¨)

**ç†ç”±**:
- âœ… è»½é‡ã§é«˜ç²¾åº¦ï¼ˆMBç´šï¼‰
- âœ… æ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œ
- âœ… TFLiteå¤‰æ›æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«æä¾›
- âœ… STM32N6ã§å‹•ä½œå®Ÿç¸¾ã‚ã‚Š
- âœ… å•†ç”¨åˆ©ç”¨å¯èƒ½ï¼ˆApache 2.0ï¼‰

**æ§‹æˆ**:
```
PaddleOCR-Lite Pipeline:
â”œâ”€â”€ Text Detection: DB (Differentiable Binarization)
â”‚   â””â”€â”€ å…¥åŠ›: 640x640 RGB â†’ å‡ºåŠ›: ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸ
â””â”€â”€ Text Recognition: CRNN
    â””â”€â”€ å…¥åŠ›: 32x320 Gray â†’ å‡ºåŠ›: æ–‡å­—åˆ—
```

**ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º**:
- Detection: 1.4MB (FP32) â†’ 400KB (INT8)
- Recognition: 2.1MB (FP32) â†’ 600KB (INT8)
- **åˆè¨ˆ**: 1.0MB (INT8é‡å­åŒ–å¾Œ)

---

### Option 2: EAST + CRNN (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¨˜è¼‰ãƒ¢ãƒ‡ãƒ«)

**ç†ç”±**:
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§æ—¢ã«è¨€åŠ
- å®Ÿè£…ä¾‹ãŒè±Šå¯Œ
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ€§ãŒé«˜ã„

**èª²é¡Œ**:
- è‡ªå‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦
- æ—¥æœ¬èªå¯¾å¿œã«è¿½åŠ ä½œæ¥­

---

## 2. PaddleOCR-Lite å®Ÿè£…æ‰‹é †

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

```bash
# PaddleOCRå…¬å¼ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
git clone https://github.com/PaddlePaddle/PaddleOCR.git
cd PaddleOCR

# è»½é‡ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
wget https://paddleocr.bj.bcebos.com/PP-OCRv4/japanese/japan_PP-OCRv4_det_infer.tar
wget https://paddleocr.bj.bcebos.com/PP-OCRv4/japanese/japan_PP-OCRv4_rec_infer.tar

tar -xf japan_PP-OCRv4_det_infer.tar
tar -xf japan_PP-OCRv4_rec_infer.tar
```

### ã‚¹ãƒ†ãƒƒãƒ—2: TFLiteå¤‰æ›

```python
# paddle2tflite.py
import paddle2onnx
import onnx
from onnx_tf.backend import prepare
import tensorflow as tf

# 1. Paddle â†’ ONNX
paddle2onnx.command.program2onnx(
    model_dir='japan_PP-OCRv4_det_infer',
    model_filename='inference.pdmodel',
    params_filename='inference.pdiparams',
    save_file='det_model.onnx',
    opset_version=11
)

# 2. ONNX â†’ TensorFlow
onnx_model = onnx.load('det_model.onnx')
tf_rep = prepare(onnx_model)
tf_rep.export_graph('det_model_tf')

# 3. TensorFlow â†’ TFLite (INT8é‡å­åŒ–)
def representative_dataset():
    import numpy as np
    for i in range(100):
        # 640x640ã®ç”»åƒã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        img = np.random.rand(1, 640, 640, 3).astype(np.float32)
        yield [img]

converter = tf.lite.TFLiteConverter.from_saved_model('det_model_tf')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model = converter.convert()
with open('det_model_int8.tflite', 'wb') as f:
    f.write(tflite_model)

print(f"âœ… Detection model: {len(tflite_model) / 1024:.2f} KB")
```

åŒæ§˜ã«èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚‚å¤‰æ›ï¼š

```python
# Recognition model (CRNN)
paddle2onnx.command.program2onnx(
    model_dir='japan_PP-OCRv4_rec_infer',
    model_filename='inference.pdmodel',
    params_filename='inference.pdiparams',
    save_file='rec_model.onnx',
    opset_version=11
)

# ä»¥ä¸‹ã€åŒã˜æµã‚Œã§TFLiteå¤‰æ›
# ...

print(f"âœ… Recognition model: {len(tflite_model) / 1024:.2f} KB")
```

### ã‚¹ãƒ†ãƒƒãƒ—3: STM32N6çµ±åˆ

```c
// src/ai/ocr_pipeline.c

#include "neural_art_hal.h"

// ãƒ¢ãƒ‡ãƒ«ãƒãƒ³ãƒ‰ãƒ«
static neural_art_handle_t det_model;
static neural_art_handle_t rec_model;

// OCRåˆæœŸåŒ–
int ocr_init(void) {
    // Detection modelèª­ã¿è¾¼ã¿
    if (neural_art_hal_load_model(
        "det_model_int8.tflite", 
        &det_model
    ) != 0) {
        return -1;
    }
    
    // Recognition modelèª­ã¿è¾¼ã¿
    if (neural_art_hal_load_model(
        "rec_model_int8.tflite",
        &rec_model
    ) != 0) {
        return -2;
    }
    
    return 0;
}

// OCRå®Ÿè¡Œ
typedef struct {
    char text[256];
    float confidence;
    int num_chars;
} ocr_result_t;

ocr_result_t ocr_recognize(uint8_t *image_640x640) {
    ocr_result_t result = {0};
    
    // 1. ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
    detection_output_t det_output;
    neural_art_hal_inference(det_model, image_640x640, &det_output);
    
    // 2. æ¤œå‡ºé ˜åŸŸã®æŠ½å‡º
    text_region_t regions[10];
    int num_regions = extract_text_regions(&det_output, regions);
    
    // 3. å„é ˜åŸŸã§æ–‡å­—èªè­˜
    char full_text[256] = {0};
    int text_pos = 0;
    
    for (int i = 0; i < num_regions; i++) {
        // é ˜åŸŸã‚’ãƒªã‚µã‚¤ã‚º (32x320)
        uint8_t region_resized[32 * 320];
        resize_region(&regions[i], region_resized, 32, 320);
        
        // CRNNæ¨è«–
        recognition_output_t rec_output;
        neural_art_hal_inference(rec_model, region_resized, &rec_output);
        
        // CTC Decoding
        char text_segment[64];
        ctc_decode(&rec_output, text_segment);
        
        // çµæœã‚’çµåˆ
        strcat(full_text, text_segment);
        text_pos += strlen(text_segment);
    }
    
    strcpy(result.text, full_text);
    result.num_chars = strlen(full_text);
    result.confidence = compute_confidence(&det_output);
    
    return result;
}
```

### ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```c
// main.c

#include "ocr_pipeline.h"
#include "camera_hal.h"
#include <stdio.h>

int main(void) {
    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    HAL_Init();
    SystemClock_Config();
    
    // OCRåˆæœŸåŒ–
    if (ocr_init() != 0) {
        printf("âŒ OCR initialization failed\n");
        return -1;
    }
    printf("âœ… OCR initialized\n");
    
    // ã‚«ãƒ¡ãƒ©åˆæœŸåŒ–
    camera_init();
    
    while (1) {
        // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£
        uint8_t *frame = camera_capture();
        
        // OCRå®Ÿè¡Œ
        ocr_result_t result = ocr_recognize(frame);
        
        // çµæœå‡ºåŠ› ğŸ¯
        if (result.num_chars > 0) {
            printf("ğŸ“ Recognized: %s\n", result.text);
            printf("   Confidence: %.2f%%\n", result.confidence * 100);
        } else {
            printf("âŒ No text detected\n");
        }
        
        // 20mså‘¨æœŸ
        HAL_Delay(20);
    }
}
```

---

## 3. ç°¡æ˜“ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ï¼‰

ãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã§ã‚‚å‹•ä½œç¢ºèªã§ãã‚‹æ–¹æ³•ï¼š

```c
// test/ocr_mock.c

// ãƒ¢ãƒƒã‚¯OCRï¼ˆæ–‡å­—åˆ—ã‚’è¿”ã™ã ã‘ï¼‰
ocr_result_t ocr_recognize_mock(uint8_t *image) {
    ocr_result_t result;
    
    // ãƒ€ãƒŸãƒ¼æ–‡å­—åˆ—ã‚’è¿”ã™
    strcpy(result.text, "Hello Î¼TRON!");
    result.confidence = 0.95f;
    result.num_chars = 13;
    
    return result;
}

// ãƒ†ã‚¹ãƒˆ
int main(void) {
    printf("=== OCR Mock Test ===\n");
    
    uint8_t dummy_image[640 * 640 * 3] = {0};
    
    ocr_result_t result = ocr_recognize_mock(dummy_image);
    
    printf("ğŸ“ Recognized: %s\n", result.text);
    printf("   Confidence: %.2f%%\n", result.confidence * 100);
    
    // âœ… æœŸå¾…å‡ºåŠ›:
    // ğŸ“ Recognized: Hello Î¼TRON!
    //    Confidence: 95.00%
    
    return 0;
}
```

---

## 4. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
utron-edge-ai-ocr/
â”œâ”€â”€ models/                      # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ ¼ç´
â”‚   â”œâ”€â”€ det_model_int8.tflite   # ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º
â”‚   â”œâ”€â”€ rec_model_int8.tflite   # æ–‡å­—èªè­˜
â”‚   â””â”€â”€ README.md                # ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±
â”‚
â”œâ”€â”€ src/ai/
â”‚   â”œâ”€â”€ ocr_pipeline.c           # OCRãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…
â”‚   â”œâ”€â”€ ocr_pipeline.h
â”‚   â”œâ”€â”€ ctc_decoder.c            # CTC Decoding
â”‚   â””â”€â”€ text_detection.c         # å¾Œå‡¦ç†
â”‚
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ ocr_mock.c               # ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ ocr_integration_test.c   # çµ±åˆãƒ†ã‚¹ãƒˆ
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ download_models.sh       # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    â””â”€â”€ convert_to_tflite.py     # TFLiteå¤‰æ›
```

---

## 5. å®Ÿè£…ã®å„ªå…ˆé †ä½

### Phase 1: ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ (1æ—¥)
```bash
âœ… Step 1: ocr_mock.cå®Ÿè£…
âœ… Step 2: ã‚·ãƒªã‚¢ãƒ«å‡ºåŠ›ç¢ºèª
âœ… Goal: "Hello Î¼TRON!" ãŒå‡ºåŠ›ã•ã‚Œã‚‹
```

### Phase 2: ãƒ¢ãƒ‡ãƒ«æº–å‚™ (2-3æ—¥)
```bash
âœ… Step 1: PaddleOCRãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
âœ… Step 2: TFLiteå¤‰æ›
âœ… Step 3: STM32CubeMXã§ãƒ¢ãƒ‡ãƒ«ç™»éŒ²
âœ… Goal: ãƒ¢ãƒ‡ãƒ«ãŒãƒ“ãƒ«ãƒ‰ã«å«ã¾ã‚Œã‚‹
```

### Phase 3: å®Ÿæ©Ÿçµ±åˆ (3-5æ—¥)
```bash
âœ… Step 1: NPUã§ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ
âœ… Step 2: ã‚«ãƒ¡ãƒ©å…¥åŠ›çµ±åˆ
âœ… Step 3: å¾Œå‡¦ç†å®Ÿè£…
âœ… Goal: å®Ÿéš›ã®æ–‡å­—ãŒèªè­˜ã•ã‚Œã‚‹ ğŸ¯
```

---

## 6. ãƒ¢ãƒ‡ãƒ«å…¥æ‰‹ã®ä»£æ›¿æ–¹æ³•

### æ–¹æ³•A: PaddleOCRå…¬å¼ (æ¨å¥¨)
```bash
# æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«
wget https://paddleocr.bj.bcebos.com/PP-OCRv4/japanese/japan_PP-OCRv4_det_infer.tar
wget https://paddleocr.bj.bcebos.com/PP-OCRv4/japanese/japan_PP-OCRv4_rec_infer.tar
```

### æ–¹æ³•B: TensorFlow Hub
```python
import tensorflow_hub as hub

# EfficientNet-based text detection
detector = hub.load("https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1")
```

### æ–¹æ³•C: è‡ªå‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
```python
# å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’
# - 1000æšã®ç”»åƒãŒã‚ã‚Œã°ååˆ†
# - æ—¥æœ¬èª: ROIS dataset
# - è‹±èª: ICDAR dataset
```

---

## 7. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### Q1: ãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã™ãã‚‹ï¼ˆ>2MBï¼‰
**A**: Pruning + é‡å­åŒ–ã§å‰Šæ¸›
```python
# 50%ã®Weightã‚’å‰Šé™¤
model = tfmot.sparsity.keras.prune_low_magnitude(model)
```

### Q2: ç²¾åº¦ãŒä½ã„ï¼ˆ<80%ï¼‰
**A**: ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ”¹å–„
```python
# å®Ÿéš›ã®æ’®å½±ç”»åƒã§ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
def representative_dataset():
    for img in real_camera_images[:100]:
        yield [preprocess(img)]
```

### Q3: NPUã§å‹•ã‹ãªã„
**A**: ãƒ¬ã‚¤ãƒ¤ãƒ¼äº’æ›æ€§ç¢ºèª
```bash
stedgeai validate --model model.tflite --target stm32n6
```

---

## 8. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### âœ… ä»Šã™ãå§‹ã‚ã‚‹
```bash
# 1. ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‹ã‚‰å§‹ã‚ã‚‹
cd test/
gcc -o ocr_mock ocr_mock.c
./ocr_mock

# æœŸå¾…å‡ºåŠ›:
# ğŸ“ Recognized: Hello Î¼TRON!
#    Confidence: 95.00%
```

### ğŸ“š è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [ãƒ¢ãƒ‡ãƒ«å¤‰æ›ã‚¬ã‚¤ãƒ‰](stm32-cube-ai-guide/03-model-conversion.md)
- [é‡å­åŒ–ã‚¬ã‚¤ãƒ‰](stm32-cube-ai-guide/04-quantization.md)
- [OCRå®Ÿè£…ä¾‹](stm32-cube-ai-guide/08-ocr-case-study.md)

---

## 9. ã¾ã¨ã‚

**ã‚´ãƒ¼ãƒ«é”æˆã¸ã®æœ€çŸ­çµŒè·¯**:

```
1. Mockå®Ÿè£… (1æ—¥)
   â””â”€> "Hello Î¼TRON!" å‡ºåŠ›ç¢ºèª âœ…

2. PaddleOCR-Liteå°å…¥ (3æ—¥)
   â””â”€> æ—¥æœ¬èªOCRãƒ¢ãƒ‡ãƒ«å‹•ä½œ âœ…

3. ã‚«ãƒ¡ãƒ©çµ±åˆ (2æ—¥)
   â””â”€> ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èªè­˜ ğŸ¯
```

**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**: **PaddleOCR-Lite (æ—¥æœ¬èªç‰ˆ)**
- ã‚µã‚¤ã‚º: 1.0MB (INT8)
- ç²¾åº¦: 95%+
- å¯¾å¿œè¨€èª: æ—¥æœ¬èªãƒ»è‹±èª
- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: Apache 2.0 âœ…

---

**æ›´æ–°æ—¥**: 2025å¹´9æœˆ30æ—¥  
**é–¢é€£Issue**: #4, #8 - Neural-ART NPUçµ±åˆãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†
