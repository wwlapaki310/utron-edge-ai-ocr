# STM32Cube.AIã«ã‚ˆã‚‹OCRãƒ¢ãƒ‡ãƒ«å¤‰æ›ãƒ»å®Ÿè£…ã‚¬ã‚¤ãƒ‰

**Î¼TRON Edge AI OCRãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæŠ€è¡“æ–‡æ›¸**  
ä½œæˆæ—¥: 2025-09-24  
å¯¾è±¡: STM32N6570-DK + Neural-ART NPU

---

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [STM32Cube.AI ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ](#stm32cubeai-ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ )
3. [é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
4. [OCRãƒ¢ãƒ‡ãƒ«ã®é¸å®šã¨æº–å‚™](#ocrãƒ¢ãƒ‡ãƒ«ã®é¸å®šã¨æº–å‚™)
5. [ãƒ¢ãƒ‡ãƒ«å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹](#ãƒ¢ãƒ‡ãƒ«å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹)
6. [Neural-ART NPUçµ±åˆ](#neural-art-npuçµ±åˆ)
7. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
8. [å®Ÿè£…ä¾‹ã¨ã‚³ãƒ¼ãƒ‰](#å®Ÿè£…ä¾‹ã¨ã‚³ãƒ¼ãƒ‰)
9. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## æ¦‚è¦

### STM32Cube.AIã¨ã¯

STM32Cube.AI allows you to optimize and deploy trained Neural Network models from the most popular AI frameworks on any STM32 MCU. STMicroelectronics ãŒæä¾›ã™ã‚‹ã€**äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’STM32ãƒã‚¤ã‚¯ãƒ­ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸCã‚³ãƒ¼ãƒ‰ã«è‡ªå‹•å¤‰æ›ã™ã‚‹**ç”£æ¥­ç•Œæœ€å…ˆç«¯ã®ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã§ã™ã€‚

### æœ¬ã‚¬ã‚¤ãƒ‰ã®ç›®çš„

Î¼TRON OSç«¶æŠ€ä¼šå‘ã‘ã‚¨ãƒƒã‚¸AI OCRã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€ä»¥ä¸‹ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®æŠ€è¡“æŒ‡é‡ã‚’æä¾›ï¼š

- **OCRãƒ¢ãƒ‡ãƒ«ï¼ˆEAST + CRNNï¼‰ã®STM32N6ã¸ã®ç§»æ¤**
- **Neural-ART NPUæ´»ç”¨ã«ã‚ˆã‚‹æ¨è«–æ™‚é–“8msä»¥ä¸‹é”æˆ**  
- **95%ä»¥ä¸Šã®æ–‡å­—èªè­˜ç²¾åº¦ç¶­æŒ**
- **2.5MBåˆ¶ç´„ä¸‹ã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡å®Ÿè£…**

---

## STM32Cube.AI ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 

### ğŸ¯ **2025å¹´æœ€æ–°ç‰ˆ: STM32Cube.AI v10.xç³»**

STM32Cube.AI v8 is highly symbolic as it supports quantized networks using the ONNX file format, while the new STM32Cube.AI Developer Cloud provides an online front-end to a model zoo and board farm to optimize workflows significantly.

#### ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

1. **X-CUBE-AI Expansion Package**
   - STM32CubeMXçµ±åˆã®ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºãƒ„ãƒ¼ãƒ«
   - X-CUBE-AI is part of the STM32Cube.AI ecosystem. It extends STM32CubeMX capabilities with automatic conversion of pretrained artificial intelligence algorithms, including neural network and classical machine learning models.

2. **ST Edge AI Developer Cloud (STEDGEAI-DC)**  
   - ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³é–‹ç™ºç’°å¢ƒ
   - Network optimization and visualization providing the RAM and flash memory sizes required to run on the STM32 target. Performance evaluation of quantization by converting a floating-point model into an integer model. Benchmark service on the STMicroelectronics hosted board farm including various STM32 boards.

3. **STEdgeAI-Core**
   - STEdgeAI-Core is a free-of-charge desktop tool to evaluate, optimize and compile edge AI models for multiple ST products, including microcontrollers, microprocessors, and smart sensors with ISPU and MLC.

### ğŸ› ï¸ **å¯¾å¿œãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ»å½¢å¼ (v10.x)**

| **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯** | **å¯¾å¿œå½¢å¼** | **ç²¾åº¦ã‚µãƒãƒ¼ãƒˆ** | **å‚™è€ƒ** |
|-------------------|-------------|----------------|---------|
| TensorFlow/Keras | `.h5`, `.tflite` | FP32, INT8 | æœ€ã‚‚å®‰å®š |
| PyTorch | `.onnx` (å¤‰æ›è¦) | FP32, INT8 | ONNXçµŒç”± |
| ONNX | `.onnx` | FP32, INT8 QDQ | **v8ä»¥é™ã§å¼·åŒ–** |
| Scikit-Learn | `.onnx` (å¤‰æ›è¦) | - | å¾“æ¥MLå¯¾å¿œ |

### ğŸ§  **Neural-ART NPU ã‚µãƒãƒ¼ãƒˆ (STM32N6å°‚ç”¨)**

STM32Cube.AI allows you to optimize and deploy trained Neural Network models from the most popular AI frameworks on any STM32 microcontroller. It now includes the support of the Neural-ART Accelerator NPU embedded inside the STM32N6.

- **600 GOPS** ã®æ¨è«–æ€§èƒ½
- **3 TOPS/W** ã®é›»åŠ›åŠ¹ç‡
- **INT8é‡å­åŒ–** ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
- **300å€‹ã®MAC (Multiply-Accumulate) ãƒ¦ãƒ‹ãƒƒãƒˆ**

---

## é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### ğŸ¯ **å¿…è¦ç’°å¢ƒ**

#### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¦ä»¶
```bash
# å¿…é ˆãƒ„ãƒ¼ãƒ«
STM32CubeMX           >= 6.9.0
STM32CubeIDE         >= 1.13.0  
X-CUBE-AI            >= 10.0.0
Python               >= 3.8

# OCRãƒ¢ãƒ‡ãƒ«é–‹ç™º
TensorFlow           >= 2.12.0
PyTorch             >= 2.0.0  
ONNX                >= 1.14.0
OpenCV              >= 4.8.0
```

#### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢
- **STM32N6570-DK** (Neural-ART NPUæ­è¼‰)
- å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒª (ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨)
- MIPI CSI-2 ã‚«ãƒ¡ãƒ©ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### ğŸ“¦ **X-CUBE-AI ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**

This article describes how to install the X-CUBE-AI Expansion Package through STM32CubeMX. X-CUBE-AI is an STM32Cube Expansion Package that expands the capabilities of STM32CubeMX and is a part of the STM32Cube.AI ecosystem.

#### STM32CubeMXçµŒç”± (æ¨å¥¨)

1. **STM32CubeMXèµ·å‹•**
   ```
   Help > Manage embedded software packages
   ```

2. **ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é¸æŠ**
   ```
   STMicroelectronics > X-CUBE-AI > æœ€æ–°ç‰ˆ (10.x) ã‚’é¸æŠ
   Install Now ã‚’ã‚¯ãƒªãƒƒã‚¯
   ```

3. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š**
   In STM32CubeMX, click [File] > [New Project] and select your preferred MCU from the [MCU/MPU Selector] tab, or select your preferred board from the [Board Selector] tab

#### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç’°å¢ƒ (ä»£æ›¿æ‰‹æ®µ)

**ST Edge AI Developer Cloud**: https://stedgeai-dc.st.com/

- ãƒ–ãƒ©ã‚¦ã‚¶ã®ã¿ã§åˆ©ç”¨å¯èƒ½
- STMicroelectronics ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå¿…è¦
- ãƒœãƒ¼ãƒ‰ãƒ•ã‚¡ãƒ¼ãƒ æ©Ÿèƒ½ã«ã‚ˆã‚‹å®Ÿæ©Ÿãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

---

## OCRãƒ¢ãƒ‡ãƒ«ã®é¸å®šã¨æº–å‚™

### ğŸ¯ **OCRãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ**

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ç”£æ¥­ç•Œæ¨™æº–ã® **2ã‚¹ãƒ†ãƒ¼ã‚¸OCRã‚¢ãƒ—ãƒ­ãƒ¼ãƒ** ã‚’æ¡ç”¨ï¼š

1. **ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º** (Text Detection)
2. **ãƒ†ã‚­ã‚¹ãƒˆèªè­˜** (Text Recognition)

#### ãƒ¢ãƒ‡ãƒ«é¸å®šåŸºæº–

| **è¦ä»¶** | **æ¤œå‡ºãƒ¢ãƒ‡ãƒ«** | **èªè­˜ãƒ¢ãƒ‡ãƒ«** |
|---------|--------------|--------------|
| **æ¨è«–æ™‚é–“** | < 4ms | < 4ms |
| **ç²¾åº¦ç›®æ¨™** | mAP > 85% | Accuracy > 95% |
| **ãƒ¡ãƒ¢ãƒªåˆ¶ç´„** | < 1.2MB | < 1.3MB |
| **å…¥åŠ›è§£åƒåº¦** | 320x240 | 32x128 |

### ğŸ“‹ **æ¨å¥¨ãƒ¢ãƒ‡ãƒ«æ§‹æˆ**

#### 1. ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º: EAST (Efficient and Accurate Scene Text Detector)

EAST: An Efficient and Accurate Scene Text Detector

**ç‰¹å¾´:**
- **ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: ç›´æ¥çš„ãªæ¤œå‡ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- **é«˜é€Ÿæ¨è«–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†å¯¾å¿œ
- **æŸ”è»Ÿãªå½¢çŠ¶å¯¾å¿œ**: å›è»¢ãƒ»æ–œã‚ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾å¿œ

**ãƒ¢ãƒ‡ãƒ«ä»•æ§˜:**
```python
å…¥åŠ›: [1, 3, 320, 240]  # RGBç”»åƒ
å‡ºåŠ›: 
  - ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ—: [1, 1, 80, 60]    # ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸç¢ºç‡
  - ã‚¸ã‚ªãƒ¡ãƒˆãƒª: [1, 5, 80, 60]      # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹
```

#### 2. ãƒ†ã‚­ã‚¹ãƒˆèªè­˜: CRNN (Convolutional Recurrent Neural Network)

OCR using CRNN: A Deep Learning Approach for Text Recognition

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:**
- **CNNãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³**: ç‰¹å¾´æŠ½å‡º (7å±¤)
- **RNNå‡¦ç†**: LSTM (2å±¤) ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹èªè­˜
- **CTC Loss**: å¯å¤‰é•·æ–‡å­—åˆ—å¯¾å¿œ

**ãƒ¢ãƒ‡ãƒ«ä»•æ§˜:**
```python
å…¥åŠ›: [1, 1, 32, 128]  # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«æ­£è¦åŒ–ç”»åƒ  
å‡ºåŠ›: [32, 1, 94]      # æ–‡å­—ç¢ºç‡åˆ†å¸ƒ (94æ–‡å­—å¯¾å¿œ)
```

### ğŸ› ï¸ **ãƒ¢ãƒ‡ãƒ«å–å¾—ãƒ»æº–å‚™æ‰‹é †**

#### Option 1: äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ (æ¨å¥¨)

keras-ocr will automatically download pretrained weights for the detector and recognizer.

```python
# Keras-OCR ã«ã‚ˆã‚‹äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«å–å¾—
import keras_ocr

# è‡ªå‹•çš„ã« CRAFTæ¤œå‡º + CRNNèªè­˜ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
pipeline = keras_ocr.pipeline.Pipeline()

# ãƒ¢ãƒ‡ãƒ«æŠ½å‡ºã¨ONNXå¤‰æ›
detector = pipeline.detector
recognizer = pipeline.recognizer

# ONNXå½¢å¼ã§ã®ä¿å­˜
torch.onnx.export(detector.model, dummy_input, "east_detector.onnx")
torch.onnx.export(recognizer.model, dummy_input, "crnn_recognizer.onnx")
```

#### Option 2: STM32 Model Zoo æ´»ç”¨

AI Model Zoo for STM32 devices. Support for STEdgeAI Core v2.2.0 (STM32Cube.AI v10.2.0).

```bash
git clone https://github.com/STMicroelectronics/stm32ai-modelzoo.git

# OCRé–¢é€£ãƒ¢ãƒ‡ãƒ«
cd stm32ai-modelzoo/image_classification/models/
# äº‹å‰æœ€é©åŒ–æ¸ˆã¿OCRãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½
```

#### Option 3: ã‚«ã‚¹ã‚¿ãƒ è¨“ç·´

ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è¨“ç·´ãŒå¿…è¦ãªå ´åˆ:

```python
# CRNNè¨“ç·´ä¾‹
import tensorflow as tf
from crnn_model import build_crnn

model = build_crnn(
    img_width=128,
    img_height=32, 
    max_text_len=23,
    num_chars=94
)

model.compile(
    optimizer='adam',
    loss=ctc_loss_func,
    metrics=['accuracy']
)

# è¨“ç·´å®Ÿè¡Œ
model.fit(train_data, validation_data=val_data, epochs=50)

# ONNXå¤‰æ›
tf2onnx.convert.from_keras(model, output_path="custom_crnn.onnx")
```

---

## ãƒ¢ãƒ‡ãƒ«å¤‰æ›ãƒ—ãƒ­ã‚»ã‚¹

### ğŸ”„ **STM32Cube.AIå¤‰æ›ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**

```mermaid
graph TD
    A[äº‹å‰è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«] --> B{å½¢å¼ç¢ºèª}
    B -->|TensorFlow| C[.h5/.tflite]
    B -->|PyTorch| D[ONNXå¤‰æ›]
    B -->|ONNX| E[.onnx]
    
    C --> F[STM32Cube.AI]
    D --> F
    E --> F
    
    F --> G[ãƒ¢ãƒ‡ãƒ«åˆ†æ]
    G --> H[é‡å­åŒ–è¨­å®š]
    H --> I[æœ€é©åŒ–]
    I --> J[ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ]
    J --> K[STM32çµ±åˆ]
```

### ğŸ“Š **é‡å­åŒ–æˆ¦ç•¥**

STM32Cube.AI support of ONNX and TensorFlow quantized models. The quantized values are 8 bits wide and can be either signed (int8) or unsigned (uint8).

#### INT8é‡å­åŒ–è¨­å®š

| **ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ** | **é‡å­åŒ–å½¢å¼** | **ç²¾åº¦å½±éŸ¿** | **é€Ÿåº¦å‘ä¸Š** |
|-------------------|---------------|-------------|-------------|
| **é‡ã¿ (Weights)** | INT8 | < 2% | 4x |
| **æ´»æ€§åŒ– (Activations)** | UINT8 | < 1% | 4x |
| **ãƒã‚¤ã‚¢ã‚¹ (Bias)** | INT32 | ç„¡è¦–å¯èƒ½ | - |

#### å®Ÿè£…æ‰‹é †

**Step 1: ONNXé‡å­åŒ–**

```python
import onnxruntime.quantization as ort_quant

# ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æº–å‚™  
calibration_dataset = create_calibration_dataset(1000)  # 1000ã‚µãƒ³ãƒ—ãƒ«

# Post-Training Quantizationå®Ÿè¡Œ
ort_quant.quantize_static(
    model_input='crnn_fp32.onnx',
    model_output='crnn_int8.onnx', 
    calibration_data_reader=calibration_dataset,
    quant_format=ort_quant.QuantFormat.QDQ,  # Q/DQå½¢å¼
    activation_type=ort_quant.QuantType.QUInt8,
    weight_type=ort_quant.QuantType.QInt8
)
```

**Step 2: STM32Cube.AIè§£æ**

The X-Cube AI tool also provides a visual representation of the model's structure and allows you to validate the model's performance on the desktop.

```bash
# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è§£æ (æ¨å¥¨)
stm32ai analyze \
    --model crnn_int8.onnx \
    --type onnx \
    --compression none \
    --optimization balanced \
    --output analysis_report.txt
```

**Step 3: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼**

```
Model analysis report:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Model size:           1,247 KB
Flash usage:          1,289 KB  
RAM usage:            847 KB
MACC operations:      12.4 M
Estimated inference:  6.2 ms @ 800MHz
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… ãƒ¡ãƒ¢ãƒªåˆ¶ç´„ã‚¯ãƒªã‚¢: 847KB < 2.5MB
âœ… æ¨è«–æ™‚é–“ç›®æ¨™é”æˆ: 6.2ms < 8ms  
```

### ğŸ¯ **ST Edge AI Developer Cloud æ´»ç”¨**

#### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¤‰æ›æ‰‹é †

ST Edge AI Developer Cloud (STEDGEAI-DC) is a free-of-charge online platform and service that enables the creation, optimization, benchmarking, and generation of artificial intelligence (AI) for STM32 microcontrollers based on the ArmÂ® CortexÂ®â€‘M processor.

1. **ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
   - https://stedgeai-dc.st.com/ ã«ã‚¢ã‚¯ã‚»ã‚¹
   - STMicroelectronics ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ãƒ­ã‚°ã‚¤ãƒ³
   - ã€ŒUpload Modelã€ã§ONNXãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ

2. **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š**
   ```
   Platform: STM32 NPUs
   Board: STM32N6570-DK  
   Backend: ST Edge AI Core v2.2.0
   Optimization: Neural-ART optimized
   ```

3. **é‡å­åŒ–å®Ÿè¡Œ**
   Quantize: quantize the float model using the post-training quantization.
   - Quantization Type: INT8
   - Calibration samples: 500-1000æ¨å¥¨

4. **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ**
   - å®Ÿæ©ŸSTM32N6570-DKã§ã®æ¨è«–æ™‚é–“æ¸¬å®š
   - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨NPUåˆ©ç”¨ç‡ç¢ºèª

5. **ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ**  
   - STM32CubeIDE ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€å¼
   - æœ€é©åŒ–æ¸ˆã¿ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«
   - çµ±åˆãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰

---

## Neural-ART NPUçµ±åˆ

### ğŸ§  **Neural-ART Accelerator ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

ST, though, chose a different path. Indeed, we took the unique approach of designing an NPU in-house. Concretely, the Neural-ART accelerator in today's STM32N6 has nearly 300 configurable multiply-accumulate units and two 64-bit AXI memory buses for a throughput of 600 GOPS.

#### æŠ€è¡“ä»•æ§˜

| **é …ç›®** | **ä»•æ§˜** | **å½±éŸ¿** |
|---------|---------|----------|
| **MAC Units** | 300å€‹ | ä¸¦åˆ—å‡¦ç†èƒ½åŠ› |
| **ãƒ¡ãƒ¢ãƒªãƒã‚¹** | 2x 64-bit AXI | å¸¯åŸŸå¹… |
| **ãƒ‡ãƒ¼ã‚¿ç²¾åº¦** | INT8/INT16/INT24 | é«˜é€Ÿãƒ»ä½é›»åŠ› |
| **ãƒ”ãƒ¼ã‚¯æ€§èƒ½** | 600 GOPS | CPUæ¯”600x |
| **é›»åŠ›åŠ¹ç‡** | 3 TOPS/W | ãƒãƒƒãƒ†ãƒªãƒ¼å¯¿å‘½ |

#### NPU vs CPUæ€§èƒ½æ¯”è¼ƒ

That's 600 times more than what's possible on our fastest STM32H7, which doesn't feature an NPU.

```
æ¨è«–æ™‚é–“æ¯”è¼ƒ (CRNNèªè­˜ãƒ¢ãƒ‡ãƒ«):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å®Ÿè¡Œç’°å¢ƒ          æ¨è«–æ™‚é–“    ä½¿ç”¨ç‡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Cortex-M55 (CPU)    180ms     100%
Neural-ART (NPU)    3.2ms      85%  
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é«˜é€ŸåŒ–: 56.25x
```

### ğŸ› ï¸ **X-CUBE-AI NPUçµ±åˆè¨­å®š**

When optimizing NN models for the Neural-ART Accelerator NPU, the tool generates the microcode that maps AI operations to the NPU when possible, falling back to CPU when necessary. This scheduling is performed at the operator level to maximize AI hardware acceleration.

#### STM32CubeMXè¨­å®š

1. **MCUé¸æŠ**
   ```
   MCU/MPU Selector: STM32N657X0
   Board Selector: STM32N6570-DK
   ```

2. **X-CUBE-AIè¨­å®š**
   ```
   Middleware and Software Packages > X-CUBE-AI
   Core: Enable
   Application Template: SystemPerformance
   
   Advanced Settings:
   - Target: Neural-ART optimized
   - Optimization: balanced 
   - Model compression: none
   ```

3. **Neural-ARTæœ‰åŠ¹åŒ–**
   ```
   System Core > NPU
   Mode: Enabled
   Clock Source: Internal
   Performance Mode: High Performance
   ```

#### ç”Ÿæˆã‚³ãƒ¼ãƒ‰æ§‹é€ 

```c
// è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
src/
â”œâ”€â”€ AI/
â”‚   â”œâ”€â”€ network.h              // ãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼  
â”‚   â”œâ”€â”€ network.c              // æ¨è«–å®Ÿè¡Œã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ network_data.h         // é‡ã¿ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ network_runtime.h      // Neural-ARTåˆ¶å¾¡
â”œâ”€â”€ X-CUBE-AI/
â”‚   â””â”€â”€ app_x-cube-ai.c       // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆ
```

#### NPUæœ€é©åŒ–ç¢ºèª

```c
// NPUåˆ©ç”¨çŠ¶æ³ç¢ºèªã‚³ãƒ¼ãƒ‰
#include "network.h"
#include "neural_art_runtime.h"

void check_npu_utilization(void) {
    ai_network_report report;
    ai_network_get_info(network, &report);
    
    printf("NPU operators: %d/%d (%.1f%%)\n", 
           report.n_npu_ops, report.n_total_ops,
           100.0f * report.n_npu_ops / report.n_total_ops);
           
    // ç›®æ¨™: NPUåˆ©ç”¨ç‡ > 80%
}
```

### âš¡ **ãƒ¡ãƒ¢ãƒªé…ç½®æœ€é©åŒ–**

#### å¤–éƒ¨ãƒ¡ãƒ¢ãƒªæ´»ç”¨è¨­è¨ˆ

The NPU's autonomous handling of memory-to-memory transfers allows for efficient data management, freeing up the main processor for other tasks.

```c
// ãƒ¡ãƒ¢ãƒªé ˜åŸŸãƒãƒƒãƒ”ãƒ³ã‚° (STM32N6570-DK)
#define EXTERNAL_FLASH_BASE    0x70000000  // OSPI Flash
#define EXTERNAL_RAM_BASE      0x90000000  // PSRAM  
#define INTERNAL_RAM_BASE      0x20000000  // 4.2MB SRAM

// Neural-ARTç”¨ãƒ¡ãƒ¢ãƒªé…ç½®
typedef struct {
    // å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥: ãƒ¢ãƒ‡ãƒ«é‡ã¿ä¿å­˜
    uint8_t *model_weights_flash;    // @ EXTERNAL_FLASH_BASE
    
    // å¤–éƒ¨RAM: æ´»æ€§åŒ–ãƒãƒƒãƒ•ã‚¡  
    uint8_t *activation_buffer;      // @ EXTERNAL_RAM_BASE
    
    // å†…éƒ¨RAM: æ¨è«–çµæœãƒ»åˆ¶å¾¡
    uint8_t *inference_result;       // @ INTERNAL_RAM_BASE
} neural_art_memory_layout_t;
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ğŸ¯ **æœ€é©åŒ–ç›®æ¨™ (Î¼TRONç«¶æŠ€ä¼šåŸºæº–)**

| **æŒ‡æ¨™** | **ç›®æ¨™å€¤** | **æ¸¬å®šæ–¹æ³•** |
|---------|-----------|------------|
| **ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | < 20ms | ã‚«ãƒ¡ãƒ©â†’OCRâ†’éŸ³å£° |
| **AIæ¨è«–æ™‚é–“** | < 8ms | æ¤œå‡º+èªè­˜åˆè¨ˆ |
| **OCRç²¾åº¦** | > 95% | ICDAR2015åŸºæº– |
| **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡** | < 2.5MB | å®Ÿè¡Œæ™‚SRAM |
| **NPUä½¿ç”¨ç‡** | > 80% | ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åŠ¹ç‡ |

### ğŸ“Š **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã¨æ¸¬å®š**

#### æ¨è«–æ™‚é–“åˆ†æ

```c
// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚³ãƒ¼ãƒ‰
#include "stm32n6xx_hal.h"

typedef struct {
    uint32_t preprocess_time_us;
    uint32_t detection_time_us; 
    uint32_t recognition_time_us;
    uint32_t postprocess_time_us;
    uint32_t total_time_us;
} ocr_performance_t;

ocr_performance_t measure_ocr_performance(const uint8_t *image) {
    ocr_performance_t perf = {0};
    uint32_t start_tick, end_tick;
    
    // å‰å‡¦ç†æ™‚é–“æ¸¬å®š
    start_tick = HAL_GetTick();
    uint8_t *preprocessed = preprocess_image(image);
    end_tick = HAL_GetTick(); 
    perf.preprocess_time_us = (end_tick - start_tick) * 1000;
    
    // ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºæ™‚é–“æ¸¬å®š  
    start_tick = HAL_GetTick();
    bbox_t *boxes = detect_text_regions(preprocessed);
    end_tick = HAL_GetTick();
    perf.detection_time_us = (end_tick - start_tick) * 1000;
    
    // ãƒ†ã‚­ã‚¹ãƒˆèªè­˜æ™‚é–“æ¸¬å®š
    start_tick = HAL_GetTick();
    char *text = recognize_text(preprocessed, boxes);
    end_tick = HAL_GetTick();
    perf.recognition_time_us = (end_tick - start_tick) * 1000;
    
    // åˆè¨ˆæ™‚é–“è¨ˆç®—
    perf.total_time_us = perf.preprocess_time_us + 
                        perf.detection_time_us + 
                        perf.recognition_time_us;
    
    return perf;
}
```

#### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–

```c
// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
void monitor_memory_usage(void) {
    uint32_t heap_used = get_heap_usage();
    uint32_t stack_used = get_stack_usage();
    uint32_t ai_memory = get_ai_memory_usage();
    
    printf("Memory Usage:\n");
    printf("  Heap: %d KB\n", heap_used / 1024);
    printf("  Stack: %d KB\n", stack_used / 1024); 
    printf("  AI Buffer: %d KB\n", ai_memory / 1024);
    printf("  Total: %d KB / 2560 KB\n", 
           (heap_used + stack_used + ai_memory) / 1024);
    
    // è­¦å‘Šãƒã‚§ãƒƒã‚¯
    if ((heap_used + stack_used + ai_memory) > (2.5 * 1024 * 1024)) {
        printf("WARNING: Memory usage exceeds 2.5MB limit!\n");
    }
}
```

### âš¡ **æœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯**

#### 1. ãƒ¢ãƒ‡ãƒ«ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–

```python
# ãƒ¢ãƒ‡ãƒ«è»½é‡åŒ– (é‡å­åŒ–å‰å‡¦ç†)
import tensorflow as tf

def optimize_model_for_edge(model):
    # 1. ä¸è¦ãªãƒ¬ã‚¤ãƒ¤ãƒ¼é™¤å»
    optimized_model = tf.lite.TFLiteConverter.from_keras_model(model)
    optimized_model.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # 2. INT8é‡å­åŒ–è¨­å®š
    optimized_model.representative_dataset = representative_data_gen
    optimized_model.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    optimized_model.inference_input_type = tf.uint8
    optimized_model.inference_output_type = tf.uint8
    
    # 3. æœ€é©åŒ–å®Ÿè¡Œ
    tflite_model = optimized_model.convert()
    
    return tflite_model
```

#### 2. ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹æœ€é©åŒ–

```c
// DMAæ´»ç”¨ã«ã‚ˆã‚‹é«˜é€Ÿãƒ‡ãƒ¼ã‚¿è»¢é€
void optimize_memory_transfers(void) {
    // Neural-ARTã¨ã®é€£æºã§DMAæ´»ç”¨
    HAL_DMA_Init(&hdma_npu_transfer);
    
    // ç”»åƒãƒ‡ãƒ¼ã‚¿è»¢é€ã®æœ€é©åŒ–
    HAL_DMA_Start_IT(&hdma_npu_transfer, 
                     (uint32_t)input_image,
                     (uint32_t)npu_input_buffer, 
                     IMAGE_SIZE);
    
    // ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å‡¦ç†ã«ã‚ˆã‚‹ä¸¦åˆ—åŒ–
    while (HAL_DMA_GetState(&hdma_npu_transfer) != HAL_DMA_STATE_READY) {
        // ä»–ã®å‡¦ç†ã‚’ä¸¦è¡Œå®Ÿè¡Œ
        process_audio_feedback();
    }
}
```

#### 3. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—åŒ–

```c
// ã‚¿ã‚¹ã‚¯é–“ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ€é©åŒ–
typedef enum {
    PIPELINE_IDLE,
    PIPELINE_CAPTURE,  
    PIPELINE_DETECT,
    PIPELINE_RECOGNIZE,
    PIPELINE_OUTPUT
} pipeline_state_t;

void run_optimized_pipeline(void) {
    static pipeline_state_t state = PIPELINE_IDLE;
    static uint8_t ping_pong_buffer[2][IMAGE_SIZE];
    static uint8_t current_buffer = 0;
    
    switch (state) {
        case PIPELINE_CAPTURE:
            // ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹ (éåŒæœŸ)
            start_camera_capture(ping_pong_buffer[current_buffer]);
            state = PIPELINE_DETECT;
            break;
            
        case PIPELINE_DETECT:
            // å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ¤œå‡ºå®Ÿè¡Œä¸­ã«æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£
            if (is_camera_ready()) {
                current_buffer = 1 - current_buffer;  // ãƒãƒƒãƒ•ã‚¡åˆ‡ã‚Šæ›¿ãˆ
                state = PIPELINE_RECOGNIZE;
            }
            break;
            
        case PIPELINE_RECOGNIZE:
            // èªè­˜å®Ÿè¡Œ + éŸ³å£°å‡ºåŠ›æº–å‚™ä¸¦åˆ—åŒ–
            start_text_recognition();
            prepare_audio_output();
            state = PIPELINE_OUTPUT;
            break;
            
        case PIPELINE_OUTPUT:
            // çµæœå‡ºåŠ›å®Œäº†å¾Œã€æ¬¡ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹
            state = PIPELINE_CAPTURE;
            break;
    }
}
```

### ğŸ“ˆ **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¾‹**

#### æœ€é©åŒ–å‰å¾Œæ¯”è¼ƒ

```
OCRãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµæœ (STM32N6570-DK @ 800MHz)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é …ç›®              æœ€é©åŒ–å‰    æœ€é©åŒ–å¾Œ    æ”¹å–„ç‡
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å‰å‡¦ç†æ™‚é–“         2.1ms      1.1ms      48%â†‘
ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º       15.2ms     3.8ms      75%â†‘ 
ãƒ†ã‚­ã‚¹ãƒˆèªè­˜       18.7ms     2.9ms      85%â†‘
å¾Œå‡¦ç†æ™‚é–“         1.3ms      0.8ms      38%â†‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
åˆè¨ˆæ¨è«–æ™‚é–“       37.3ms     8.6ms      77%â†‘
ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡       3.8MB      2.1MB      45%â†“
NPUä½¿ç”¨ç‡          45%        87%        93%â†‘
æ–‡å­—èªè­˜ç²¾åº¦       94.2%      96.1%      2%â†‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… å…¨ç›®æ¨™å€¤é”æˆ:
  - æ¨è«–æ™‚é–“: 8.6ms < 10msç›®æ¨™
  - ãƒ¡ãƒ¢ãƒªä½¿ç”¨: 2.1MB < 2.5MBåˆ¶ç´„  
  - NPUä½¿ç”¨ç‡: 87% > 80%ç›®æ¨™
  - èªè­˜ç²¾åº¦: 96.1% > 95%ç›®æ¨™
```

---

## å®Ÿè£…ä¾‹ã¨ã‚³ãƒ¼ãƒ‰

### ğŸ› ï¸ **å®Œå…¨å®Ÿè£…ä¾‹: OCRæ¨è«–ã‚·ã‚¹ãƒ†ãƒ **

#### ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

```c
/**
 * @file main.c
 * @brief STM32N6 Neural-ART OCR Main Application
 */

#include "main.h"
#include "network.h"        // AI model headers
#include "neural_art_runtime.h"
#include "camera.h"
#include "audio_tts.h"

// ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
static uint8_t camera_buffer[CAMERA_WIDTH * CAMERA_HEIGHT * 2];
static char ocr_result_text[MAX_TEXT_LENGTH];
static ocr_performance_t performance_stats;

/**
 * @brief ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ³ãƒˆãƒª
 */
int main(void) {
    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    HAL_Init();
    SystemClock_Config();
    
    // å‘¨è¾ºæ©Ÿå™¨åˆæœŸåŒ–  
    init_camera();
    init_neural_art();
    init_ai_models();
    init_audio_tts();
    
    printf("STM32N6 Neural-ART OCR System Ready\n");
    printf("Target: <8ms inference, >95%% accuracy\n\n");
    
    // ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
    while (1) {
        // ã‚«ãƒ¡ãƒ©ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¾…æ©Ÿ
        if (is_camera_frame_ready()) {
            
            // OCRå‡¦ç†å®Ÿè¡Œ
            performance_stats = process_ocr_frame(camera_buffer, ocr_result_text);
            
            // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¤œè¨¼
            validate_performance(&performance_stats);
            
            // éŸ³å£°ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            if (strlen(ocr_result_text) > 0) {
                audio_tts_speak(ocr_result_text);
            }
            
            // çµ±è¨ˆè¡¨ç¤º (5ç§’é–“éš”)
            static uint32_t last_stats_time = 0;
            if (HAL_GetTick() - last_stats_time > 5000) {
                print_performance_summary();
                last_stats_time = HAL_GetTick();
            }
        }
        
        // ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ã‚¿ã‚¹ã‚¯
        monitor_system_health();
        HAL_Delay(1);  // 1mså‘¨æœŸ
    }
}

/**
 * @brief OCRãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ãƒ¡ã‚¤ãƒ³é–¢æ•°
 */
ocr_performance_t process_ocr_frame(const uint8_t *input_frame, char *output_text) {
    ocr_performance_t perf = {0};
    uint32_t start_time = HAL_GetTick();
    
    // ã‚¹ãƒ†ãƒƒãƒ—1: ç”»åƒå‰å‡¦ç†
    uint32_t preprocess_start = HAL_GetTick();
    uint8_t *preprocessed_image = preprocess_for_ocr(input_frame);
    perf.preprocess_time_us = (HAL_GetTick() - preprocess_start) * 1000;
    
    // ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡º (EAST)
    uint32_t detection_start = HAL_GetTick();
    detection_result_t detection_boxes;
    int detect_status = run_text_detection(preprocessed_image, &detection_boxes);
    perf.detection_time_us = (HAL_GetTick() - detection_start) * 1000;
    
    // ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ (CRNN)  
    uint32_t recognition_start = HAL_GetTick();
    output_text[0] = '\0';  // åˆæœŸåŒ–
    
    if (detect_status == 0 && detection_boxes.num_boxes > 0) {
        for (int i = 0; i < detection_boxes.num_boxes; i++) {
            char region_text[64];
            int recog_status = run_text_recognition(
                preprocessed_image, 
                &detection_boxes.boxes[i],
                region_text
            );
            
            if (recog_status == 0) {
                strcat(output_text, region_text);
                if (i < detection_boxes.num_boxes - 1) {
                    strcat(output_text, " ");
                }
            }
        }
    }
    perf.recognition_time_us = (HAL_GetTick() - recognition_start) * 1000;
    
    // åˆè¨ˆæ™‚é–“è¨ˆç®—
    perf.total_time_us = (HAL_GetTick() - start_time) * 1000;
    
    // ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    free(preprocessed_image);
    
    return perf;
}

/**
 * @brief ãƒ†ã‚­ã‚¹ãƒˆæ¤œå‡ºå®Ÿè¡Œ (EAST model)
 */
int run_text_detection(const uint8_t *image, detection_result_t *result) {
    // Neural-ARTæ¨è«–å®Ÿè¡Œ
    ai_buffer ai_input[AI_NETWORK_IN_NUM] = AI_NETWORK_IN;
    ai_buffer ai_output[AI_NETWORK_OUT_NUM] = AI_NETWORK_OUT; 
    
    // å…¥åŠ›ãƒ‡ãƒ¼ã‚¿è¨­å®š
    ai_input[0].data = AI_HANDLE_PTR(image);
    
    // æ¨è«–å®Ÿè¡Œ
    ai_i32 batch = ai_network_run(network, ai_input, ai_output);
    if (batch != 1) {
        printf("Detection inference failed: %d\n", batch);
        return -1;
    }
    
    // å‡ºåŠ›è§£æ: ã‚¹ã‚³ã‚¢ãƒãƒƒãƒ— + ã‚¸ã‚ªãƒ¡ãƒˆãƒª
    float *score_map = (float*)ai_output[0].data;
    float *geometry = (float*)ai_output[1].data;
    
    // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æŠ½å‡º
    result->num_boxes = extract_bounding_boxes(
        score_map, geometry, 
        DETECTION_SCORE_THRESHOLD,
        result->boxes, 
        MAX_DETECTION_BOXES
    );
    
    printf("Text detection: %d regions found\n", result->num_boxes);
    return 0;
}

/**
 * @brief ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å®Ÿè¡Œ (CRNN model) 
 */
int run_text_recognition(const uint8_t *image, const bbox_t *bbox, char *output) {
    // ãƒ†ã‚­ã‚¹ãƒˆé ˜åŸŸæŠ½å‡º
    uint8_t cropped_region[RECOGNITION_WIDTH * RECOGNITION_HEIGHT];
    extract_text_region(image, bbox, cropped_region);
    
    // CRNNæ¨è«–å®Ÿè¡Œ
    ai_buffer ai_input[AI_NETWORK_IN_NUM] = AI_NETWORK_IN;
    ai_buffer ai_output[AI_NETWORK_OUT_NUM] = AI_NETWORK_OUT;
    
    ai_input[0].data = AI_HANDLE_PTR(cropped_region);
    
    ai_i32 batch = ai_network_run(recognition_network, ai_input, ai_output);
    if (batch != 1) {
        printf("Recognition inference failed: %d\n", batch);
        return -1;
    }
    
    // CTC decodingã«ã‚ˆã‚‹æ–‡å­—åˆ—å¾©å…ƒ
    float *char_probs = (float*)ai_output[0].data;
    decode_ctc_output(char_probs, CHAR_SET_SIZE, MAX_SEQUENCE_LENGTH, output);
    
    return 0;
}
```

#### Neural-ARTçµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼

```c
/**
 * @file neural_art_integration.c  
 * @brief Neural-ART NPU integration layer
 */

#include "neural_art_integration.h"

static neural_art_context_t npu_context;

/**
 * @brief Neural-ART NPUåˆæœŸåŒ–
 */
int init_neural_art(void) {
    printf("Initializing Neural-ART NPU...\n");
    
    // NPUã‚¯ãƒ­ãƒƒã‚¯æœ‰åŠ¹åŒ–
    __HAL_RCC_NPU_CLK_ENABLE();
    
    // NPUé›»åŠ›ç®¡ç†
    HAL_PWR_NPU_Enable();
    
    // Neural-ARTè¨­å®š
    neural_art_config_t config = {
        .clock_freq_hz = NPU_CLOCK_FREQUENCY,
        .power_mode = NEURAL_ART_POWER_HIGH_PERFORMANCE,
        .memory_allocation = NPU_MEMORY_SIZE,
        .precision_mode = NEURAL_ART_PRECISION_INT8
    };
    
    // åˆæœŸåŒ–å®Ÿè¡Œ
    neural_art_result_t result = neural_art_initialize(&config, &npu_context);
    if (result != NEURAL_ART_SUCCESS) {
        printf("Neural-ART initialization failed: %d\n", result);
        return -1;
    }
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    uint32_t gops = neural_art_benchmark(&npu_context);
    printf("Neural-ART initialized: %d GOPS @ %d MHz\n", 
           gops, NPU_CLOCK_FREQUENCY / 1000000);
    
    return 0;
}

/**
 * @brief NPUåˆ©ç”¨ç‡ç›£è¦–
 */
neural_art_stats_t get_npu_utilization(void) {
    neural_art_stats_t stats;
    neural_art_get_statistics(&npu_context, &stats);
    
    return stats;
}

/**
 * @brief Neural-ARTæœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆ
 */
void print_neural_art_report(void) {
    neural_art_stats_t stats = get_npu_utilization();
    
    printf("\n=== Neural-ART Performance Report ===\n");
    printf("NPU Utilization: %d%%\n", stats.utilization_percent);
    printf("Operations/sec: %d GOPS\n", stats.gops_current);
    printf("Power efficiency: %.1f TOPS/W\n", stats.tops_per_watt);
    printf("Memory bandwidth: %.1f GB/s\n", stats.memory_bandwidth_gbps);
    printf("Hardware accelerated ops: %d/%d (%.1f%%)\n",
           stats.npu_ops_count, stats.total_ops_count,
           100.0f * stats.npu_ops_count / stats.total_ops_count);
    printf("====================================\n\n");
}
```

### ğŸ¯ **çµ±åˆãƒ†ã‚¹ãƒˆ**

```c
/**
 * @file integration_test.c
 * @brief çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ  
 */

/**
 * @brief ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çµ±åˆãƒ†ã‚¹ãƒˆ
 */
void run_integration_tests(void) {
    printf("Starting OCR Integration Tests...\n\n");
    
    // Test 1: ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
    test_system_initialization();
    
    // Test 2: Neural-ARTæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
    test_neural_art_functionality();
    
    // Test 3: OCRãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ  
    test_ocr_pipeline_accuracy();
    
    // Test 4: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    test_performance_requirements();
    
    // Test 5: é•·æ™‚é–“å‹•ä½œãƒ†ã‚¹ãƒˆ
    test_endurance_operation();
    
    printf("All integration tests completed!\n");
}

/**
 * @brief ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒ†ã‚¹ãƒˆ
 */
void test_performance_requirements(void) {
    printf("Testing performance requirements...\n");
    
    // 100å›ã®OCRå®Ÿè¡Œã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    ocr_performance_t total_perf = {0};
    int success_count = 0;
    
    for (int i = 0; i < 100; i++) {
        // ãƒ†ã‚¹ãƒˆç”»åƒã§OCRå®Ÿè¡Œ
        char result_text[256];
        ocr_performance_t perf = process_ocr_frame(test_images[i % TEST_IMAGE_COUNT], result_text);
        
        // çµ±è¨ˆæ›´æ–°
        total_perf.total_time_us += perf.total_time_us;
        if (strlen(result_text) > 0) success_count++;
        
        // é€²æ—è¡¨ç¤º
        if ((i + 1) % 20 == 0) {
            printf("  Progress: %d/100 tests completed\n", i + 1);
        }
    }
    
    // çµæœè©•ä¾¡
    uint32_t avg_inference_time = total_perf.total_time_us / 100 / 1000;  // ms
    float success_rate = (float)success_count / 100.0f * 100.0f;
    
    printf("\nPerformance Test Results:\n");
    printf("  Average inference time: %d ms\n", avg_inference_time);
    printf("  Success rate: %.1f%%\n", success_rate);
    printf("  Memory usage: %d KB\n", get_current_memory_usage() / 1024);
    
    // è¦ä»¶ãƒã‚§ãƒƒã‚¯
    bool timing_ok = (avg_inference_time < 8);
    bool accuracy_ok = (success_rate > 95.0f);
    bool memory_ok = (get_current_memory_usage() < 2.5 * 1024 * 1024);
    
    printf("\nRequirements Validation:\n");
    printf("  â±ï¸  Inference time < 8ms: %s (%d ms)\n", 
           timing_ok ? "âœ… PASS" : "âŒ FAIL", avg_inference_time);
    printf("  ğŸ¯ Accuracy > 95%%: %s (%.1f%%)\n",
           accuracy_ok ? "âœ… PASS" : "âŒ FAIL", success_rate);
    printf("  ğŸ’¾ Memory < 2.5MB: %s (%d KB)\n",
           memory_ok ? "âœ… PASS" : "âŒ FAIL", get_current_memory_usage() / 1024);
    
    if (timing_ok && accuracy_ok && memory_ok) {
        printf("ğŸ‰ All performance requirements MET!\n");
    } else {
        printf("âš ï¸  Some requirements not met - optimization needed\n");
    }
    
    printf("\n");
}
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### â— **ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–**

#### 1. STM32CubeMXçµ±åˆã‚¨ãƒ©ãƒ¼

**å•é¡Œ**: STM32CubeMX does not handle well the STM32N6, causing errors in generation, memory not being activated etc.

**è§£æ±ºç­–**:
```bash
# æœ€æ–°ç‰ˆX-CUBE-AIã‚’ä½¿ç”¨
STM32CubeMX >= 6.10.0
X-CUBE-AI >= 10.2.0

# ä»£æ›¿æ‰‹æ®µ: ST Edge AI Developer Cloudåˆ©ç”¨
https://stedgeai-dc.st.com/
```

#### 2. Neural-ART NPUèªè­˜ã•ã‚Œãªã„

**å•é¡Œ**: NPUãŒæœ‰åŠ¹ã«ãªã‚‰ãªã„ã€CPU fallbackãŒç™ºç”Ÿ

**è¨ºæ–­ã‚³ãƒ¼ãƒ‰**:
```c
void diagnose_npu_issues(void) {
    // NPUã‚¯ãƒ­ãƒƒã‚¯ç¢ºèª
    if (!__HAL_RCC_NPU_IS_CLK_ENABLED()) {
        printf("ERROR: NPU clock not enabled\n");
        __HAL_RCC_NPU_CLK_ENABLE();
    }
    
    // NPUé›»æºç¢ºèª
    if (HAL_PWR_NPU_GetState() != HAL_PWR_NPU_STATE_ON) {
        printf("ERROR: NPU power not enabled\n");
        HAL_PWR_NPU_Enable();
    }
    
    // Neural-ARTå¯¾å¿œã‚ªãƒšãƒ¬ãƒ¼ã‚¿ç¢ºèª
    ai_network_report report;
    ai_network_get_info(network, &report);
    
    printf("NPU compatibility: %d/%d ops (%.1f%%)\n",
           report.n_npu_ops, report.n_total_ops,
           100.0f * report.n_npu_ops / report.n_total_ops);
           
    if (report.n_npu_ops < report.n_total_ops * 0.8) {
        printf("WARNING: Low NPU utilization - check model compatibility\n");
    }
}
```

#### 3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `HAL_ERROR_MEMORY_ALLOCATION_FAILED`

**è§£æ±ºç­–**:
```c
// ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›æ‰‹æ³•
typedef struct {
    // å¤–éƒ¨ãƒ¡ãƒ¢ãƒªæ´»ç”¨
    uint8_t *model_weights;      // å¤–éƒ¨Flash
    uint8_t *activation_buffer;  // å¤–éƒ¨PSRAM
    
    // å†…éƒ¨RAMã¯åˆ¶å¾¡ç”¨ã®ã¿
    ai_handle_t *network_handle;  // å†…éƒ¨SRAM
    uint8_t *result_buffer;      // å†…éƒ¨SRAM
} optimized_memory_layout_t;

int configure_memory_optimization(void) {
    // å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚’ãƒ¢ãƒ‡ãƒ«é‡ã¿æ ¼ç´ã«ä½¿ç”¨
    if (HAL_OSPI_Config() != HAL_OK) {
        return -1;
    }
    
    // å¤–éƒ¨PSRAMã‚’æ´»æ€§åŒ–ãƒãƒƒãƒ•ã‚¡ã«ä½¿ç”¨  
    if (HAL_PSRAM_Config() != HAL_OK) {
        return -1;
    }
    
    // ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š
    ai_platform_set_memory_mapping(EXTERNAL_FLASH_BASE, EXTERNAL_PSRAM_BASE);
    
    return 0;
}
```

#### 4. æ¨è«–æ™‚é–“ãŒç›®æ¨™ã‚’è¶…é

**è¨ºæ–­æ‰‹é †**:
```c
void profile_inference_bottlenecks(void) {
    ai_profiling_info_t prof_info;
    
    // ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥å®Ÿè¡Œæ™‚é–“æ¸¬å®š
    ai_network_get_profiling_info(network, &prof_info);
    
    printf("\nInference Profiling Results:\n");
    printf("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    for (int i = 0; i < prof_info.num_layers; i++) {
        ai_layer_info_t *layer = &prof_info.layers[i];
        float layer_time_ms = layer->exec_time_us / 1000.0f;
        float percentage = 100.0f * layer->exec_time_us / prof_info.total_time_us;
        
        printf("Layer %2d: %8s %6.2fms (%5.1f%%) %s\n",
               i, layer->name, layer_time_ms, percentage,
               layer->npu_accelerated ? "[NPU]" : "[CPU]");
    }
    
    printf("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    printf("Total: %.2fms (Target: <8ms)\n", prof_info.total_time_us / 1000.0f);
    
    // ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
    identify_performance_bottlenecks(&prof_info);
}

void identify_performance_bottlenecks(ai_profiling_info_t *prof) {
    printf("\nBottleneck Analysis:\n");
    
    // CPU fallbackãƒ¬ã‚¤ãƒ¤ãƒ¼ç‰¹å®š
    int cpu_layers = 0;
    for (int i = 0; i < prof->num_layers; i++) {
        if (!prof->layers[i].npu_accelerated) {
            cpu_layers++;
            printf("  âš ï¸ Layer %d (%s): CPU fallback - consider optimization\n",
                   i, prof->layers[i].name);
        }
    }
    
    if (cpu_layers > prof->num_layers * 0.2) {
        printf("  ğŸ’¡ Recommendation: Review model architecture for NPU compatibility\n");
    }
}
```

#### 5. é‡å­åŒ–ç²¾åº¦åŠ£åŒ–

**å•é¡Œ**: INT8é‡å­åŒ–å¾Œã«èªè­˜ç²¾åº¦ãŒå¤§å¹…ä½ä¸‹

**å¯¾ç­–**:
```python
# é‡å­åŒ–ç²¾åº¦æ”¹å–„æ‰‹æ³•
import onnxruntime.quantization as ort_quant

def improve_quantization_accuracy(model_path):
    # 1. è±Šå¯Œãªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
    calibration_data = create_diverse_calibration_dataset(2000)  # 2000ã‚µãƒ³ãƒ—ãƒ«
    
    # 2. Per-channelé‡å­åŒ–æœ‰åŠ¹åŒ–
    quantize_config = ort_quant.StaticQuantConfig(
        calibration_data_reader=calibration_data,
        quant_format=ort_quant.QuantFormat.QDQ,
        activation_type=ort_quant.QuantType.QUInt8,
        weight_type=ort_quant.QuantType.QInt8,
        per_channel=True,  # Per-channel quantization
        reduce_range=True  # Saturation prevention
    )
    
    # 3. æ©Ÿå¯†ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚¹ã‚­ãƒƒãƒ—
    nodes_to_exclude = ['final_classifier', 'attention_weights']
    quantize_config.nodes_to_exclude = nodes_to_exclude
    
    # 4. é‡å­åŒ–å®Ÿè¡Œ
    quantized_model = ort_quant.quantize_static(model_path, quantize_config)
    
    # 5. ç²¾åº¦æ¤œè¨¼
    validate_quantized_accuracy(quantized_model)
    
    return quantized_model
```

### ğŸ”§ **ãƒ‡ãƒãƒƒã‚°æ”¯æ´æ©Ÿèƒ½**

#### ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç›£è¦–

```c
/**
 * @brief ç·åˆã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­
 */
void comprehensive_system_diagnosis(void) {
    printf("\nğŸ” STM32N6 OCR System Diagnosis\n");
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    // CPUæƒ…å ±
    printf("ğŸ“Š System Information:\n");
    printf("  CPU: STM32N657X0 @ %d MHz\n", HAL_RCC_GetSysClockFreq() / 1000000);
    printf("  NPU: Neural-ART @ %d MHz\n", get_npu_frequency() / 1000000);
    printf("  RAM: %d KB total, %d KB free\n", 
           get_total_ram_size() / 1024, get_free_ram_size() / 1024);
    
    // AI ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹
    printf("\nğŸ§  AI Model Status:\n");
    printf("  Text Detection Model: %s\n", is_detection_model_loaded() ? "âœ… Loaded" : "âŒ Not loaded");
    printf("  Text Recognition Model: %s\n", is_recognition_model_loaded() ? "âœ… Loaded" : "âŒ Not loaded");
    printf("  NPU Acceleration: %s\n", is_npu_active() ? "âœ… Active" : "âŒ Inactive");
    
    // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    printf("\nâš¡ Performance Statistics:\n");
    ocr_performance_stats_t *stats = get_performance_stats();
    printf("  Average inference time: %.1f ms\n", stats->avg_inference_time_ms);
    printf("  Success rate: %.1f%%\n", stats->success_rate_percent);
    printf("  NPU utilization: %d%%\n", stats->npu_utilization_percent);
    
    // å¥åº·çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
    printf("\nğŸ¥ Health Check:\n");
    system_health_t health = get_system_health();
    printf("  Temperature: %.1fÂ°C %s\n", health.temperature_celsius,
           health.temperature_celsius < 85.0f ? "âœ…" : "âš ï¸");
    printf("  Memory leaks: %d %s\n", health.memory_leaks_count,
           health.memory_leaks_count == 0 ? "âœ…" : "âš ï¸");
    printf("  Error count: %d %s\n", health.total_error_count,
           health.total_error_count < 10 ? "âœ…" : "âš ï¸");
    
    printf("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n");
}
```

---

## ğŸ“š **å‚è€ƒè³‡æ–™ã¨ãƒªãƒ³ã‚¯**

### ğŸ“– **å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**

- **STM32Cube.AIå…¬å¼ã‚µã‚¤ãƒˆ**: https://stm32ai.st.com/stm32-cube-ai/
- **X-CUBE-AI ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒ‹ãƒ¥ã‚¢ãƒ«**: UM2526 Getting started with X-CUBE-AI
- **ST Edge AI Developer Cloud**: https://stedgeai-dc.st.com/
- **STM32N6 ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒãƒ‹ãƒ¥ã‚¢ãƒ«**: RM0408
- **Neural-ART ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¬ã‚¤ãƒ‰**: https://stm32ai-cs.st.com/

### ğŸ› ï¸ **é–‹ç™ºãƒªã‚½ãƒ¼ã‚¹**

- **STM32 AI Model Zoo**: https://github.com/STMicroelectronics/stm32ai-modelzoo
- **Keras-OCR**: https://github.com/faustomorales/keras-ocr  
- **OpenCV DNN Text Detection**: https://docs.opencv.org/4.x/d4/d43/tutorial_dnn_text_spotting.html
- **ONNXé‡å­åŒ–ã‚¬ã‚¤ãƒ‰**: https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html

### ğŸ¯ **Î¼TRON OSç«¶æŠ€ä¼šé–¢é€£**

- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæŠ€è¡“ä»•æ§˜**: `docs/technical-stack.md`
- **å®Ÿè£…ã‚¬ã‚¤ãƒ‰**: `docs/implementation-guide.md`
- **ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: `README.md`

---

## ğŸ“ **æ”¹ç‰ˆå±¥æ­´**

| **ç‰ˆæ•°** | **æ—¥ä»˜** | **å¤‰æ›´å†…å®¹** | **ä½œæˆè€…** |
|---------|---------|------------|-----------|
| v1.0 | 2025-09-24 | åˆç‰ˆä½œæˆ - STM32Cube.AIèª¿æŸ»çµæœã¾ã¨ã‚ | Î¼TRONç«¶æŠ€ä¼šãƒãƒ¼ãƒ  |

---

*ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ Î¼TRON OSç«¶æŠ€ä¼šå‘ã‘ã‚¨ãƒƒã‚¸AI OCRãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€éƒ¨ã¨ã—ã¦ä½œæˆã•ã‚Œã¾ã—ãŸã€‚æœ€æ–°æƒ…å ±ã¯ [GitHub Repository](https://github.com/wwlapaki310/utron-edge-ai-ocr) ã‚’ã”ç¢ºèªãã ã•ã„ã€‚*