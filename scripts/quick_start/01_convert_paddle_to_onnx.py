#!/usr/bin/env python3
"""\nPaddleOCR ãƒ¢ãƒ‡ãƒ«ã‚’ ONNX ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n\nä½¿ã„æ–¹:\n  python 01_convert_paddle_to_onnx.py\n\nå‡ºåŠ›:\n  ocr_model.onnx - STM32Cube.AI ã§ä½¿ç”¨å¯èƒ½ãª ONNX ãƒ¢ãƒ‡ãƒ«\n"""

import os
import sys
import urllib.request
import tarfile

try:
    import paddle
    import paddle2onnx
except ImportError:
    print("âŒ å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    print("\nä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
    print("  pip install paddlepaddle paddle2onnx onnx")
    sys.exit(1)

def download_paddle_model():
    """PaddleOCR è‹±èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    model_url = "https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar"
    model_tar = "en_PP-OCRv3_rec_infer.tar"
    model_dir = "en_PP-OCRv3_rec_infer"
    
    if os.path.exists(model_dir):
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™: {model_dir}")
        return model_dir
    
    print(f"ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {model_url}")
    
    try:
        urllib.request.urlretrieve(model_url, model_tar)
        print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {model_tar}")
        
        # è§£å‡
        print(f"ğŸ“¦ è§£å‡ä¸­...")
        with tarfile.open(model_tar) as tar:
            tar.extractall()
        
        print(f"âœ… è§£å‡å®Œäº†: {model_dir}")
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        os.remove(model_tar)
        
        return model_dir
        
    except Exception as e:
        print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

def convert_to_onnx(model_dir, output_file="ocr_model.onnx"):
    """Paddle ãƒ¢ãƒ‡ãƒ«ã‚’ ONNX ã«å¤‰æ›"""
    model_file = os.path.join(model_dir, "inference.pdmodel")
    params_file = os.path.join(model_dir, "inference.pdiparams")
    
    if not os.path.exists(model_file):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_file}")
        sys.exit(1)
    
    if not os.path.exists(params_file):
        print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {params_file}")
        sys.exit(1)
    
    print(f"\nğŸ”„ ONNX å¤‰æ›ä¸­...")
    print(f"  å…¥åŠ›ãƒ¢ãƒ‡ãƒ«: {model_file}")
    print(f"  å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    
    try:
        # ONNX å¤‰æ›
        onnx_model = paddle2onnx.command.c_paddle_to_onnx(
            model_file=model_file,
            params_file=params_file,
            save_file=output_file,
            opset_version=11,
            enable_onnx_checker=True
        )
        
        if onnx_model:
            size_mb = os.path.getsize(output_file) / (1024 * 1024)
            print(f"\nâœ… ONNX å¤‰æ›å®Œäº†!")
            print(f"  ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
            print(f"  ã‚µã‚¤ã‚º: {size_mb:.2f} MB")
            
            if size_mb > 2.5:
                print(f"\nâš ï¸  è­¦å‘Š: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒ 2.5MB ã‚’è¶…ãˆã¦ã„ã¾ã™")
                print(f"  STM32N6 ã§å‹•ä½œã•ã›ã‚‹ã«ã¯é‡å­åŒ–ãŒå¿…è¦ã§ã™")
                print(f"  æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ— (02_convert_to_stm32.sh) ã§è‡ªå‹•çš„ã«é‡å­åŒ–ã•ã‚Œã¾ã™")
            
            return True
        else:
            print(f"âŒ ONNX å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def verify_onnx_model(onnx_file):
    """ONNX ãƒ¢ãƒ‡ãƒ«ã‚’æ¤œè¨¼"""
    try:
        import onnx
        
        print(f"\nğŸ” ONNX ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ä¸­...")
        model = onnx.load(onnx_file)
        onnx.checker.check_model(model)
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼æˆåŠŸ")
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        print(f"\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
        print(f"  IR ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model.ir_version}")
        print(f"  ãƒ—ãƒ­ãƒ‡ãƒ¥ãƒ¼ã‚µãƒ¼: {model.producer_name}")
        print(f"  Opset ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {model.opset_import[0].version}")
        
        # å…¥å‡ºåŠ›æƒ…å ±
        print(f"\n  å…¥åŠ›:")
        for input in model.graph.input:
            shape = [dim.dim_value if dim.dim_value > 0 else '?' 
                    for dim in input.type.tensor_type.shape.dim]
            print(f"    {input.name}: {shape}")
        
        print(f"\n  å‡ºåŠ›:")
        for output in model.graph.output:
            shape = [dim.dim_value if dim.dim_value > 0 else '?' 
                    for dim in output.type.tensor_type.shape.dim]
            print(f"    {output.name}: {shape}")
        
        return True
        
    except Exception as e:
        print(f"âš ï¸  ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"  (å¤‰æ›ã¯æˆåŠŸã—ã¦ã„ã¾ã™ãŒã€æ¤œè¨¼ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ)")
        return False

def main():
    print("="*60)
    print("  PaddleOCR â†’ ONNX å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*60)
    print()
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    model_dir = download_paddle_model()
    
    # ONNX å¤‰æ›
    output_file = "ocr_model.onnx"
    if convert_to_onnx(model_dir, output_file):
        # æ¤œè¨¼
        verify_onnx_model(output_file)
        
        print("\n" + "="*60)
        print("âœ… ã™ã¹ã¦å®Œäº†!")
        print("="*60)
        print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  bash 02_convert_to_stm32.sh")
        print()
    else:
        print("\nâŒ å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

if __name__ == "__main__":
    main()
